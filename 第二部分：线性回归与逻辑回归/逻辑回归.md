# 逻辑回归

## 基本介绍

逻辑回归是在线性回归的基础上，结合对数几率函数“$Sigmoid$函数”，以获取某件事情发生的概率，从而改进来的二分类机器学习算法。

考虑二分类任务，其输出标记为：$y \in \{0,1\}$，而线性回归模型产生的预测值是$z=\omega^Tx+b$为实数值，于是，我们需要将实数$z$转换成$0/1$值，最理想的是单位阶跃函数（但它不连续，我们不使用）。

更多的，我们使用对数几率函数：
$$
y=\frac{1}{1+e^{-z}}
$$
代入$z=\omega^Tx+b$并进行变换，得到如下式子：
$$
ln\frac{y}{1-y}=\omega^Tx+b
$$
可以将$y$视为样本$x$作为正例的可能性，则$1-y$为样本$x$作为反例的可能性。

则有：
$$
ln\frac{p(y=1|x)}{p(y=0|x)}=\omega^Tx+b
$$

$$
p(y=1|x)=\frac{e^{\omega^Tx+b}}{1+e^{\omega^Tx+b}}
$$

$$
p(y=0|x)=\frac{1}{1+e^{\omega^Tx+b}}
$$

## 损失函数

最大化对数似然
$$
g(\omega,b)=\Sigma_{i=1}^mlnp(y_i|x_i;\omega,b)
$$
